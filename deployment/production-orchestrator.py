"""
Production Deployment Orchestrator for Causal UI Gym

Comprehensive production deployment automation with health checks,
scaling, monitoring, and disaster recovery capabilities.
"""

import asyncio
import subprocess
import time
import json
import logging
import yaml
import os
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import docker
import requests
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class DeploymentStage(Enum):
    """Deployment pipeline stages"""
    PREPARATION = "preparation"
    BUILD = "build"
    TEST = "test"
    DEPLOY = "deploy"
    VALIDATE = "validate"
    MONITOR = "monitor"
    COMPLETE = "complete"
    ROLLBACK = "rollback"
    FAILED = "failed"


class ServiceStatus(Enum):
    """Service health status"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"
    STARTING = "starting"
    STOPPED = "stopped"


@dataclass
class DeploymentConfig:
    """Production deployment configuration"""
    environment: str = "production"
    project_name: str = "causal-ui-gym"
    compose_file: str = "docker-compose.production-ready.yml"
    health_check_timeout: int = 300  # seconds
    max_rollback_attempts: int = 3
    monitoring_enabled: bool = True
    auto_scaling_enabled: bool = True
    backup_enabled: bool = True
    ssl_enabled: bool = True
    load_balancing_enabled: bool = True
    
    # Resource limits
    max_cpu_cores: int = 16
    max_memory_gb: int = 32
    max_disk_gb: int = 100
    
    # Scaling thresholds
    scale_up_cpu_threshold: float = 0.8
    scale_down_cpu_threshold: float = 0.3
    scale_up_memory_threshold: float = 0.8
    min_replicas: int = 2
    max_replicas: int = 10
    
    # Service endpoints
    services: Dict[str, Dict[str, Any]] = field(default_factory=lambda: {
        'frontend': {
            'port': 3000,
            'health_endpoint': '/health',
            'replicas': 2
        },
        'backend': {
            'port': 8002,
            'health_endpoint': '/health',
            'replicas': 3
        },
        'prometheus': {
            'port': 9090,
            'health_endpoint': '/-/healthy',
            'replicas': 1
        },
        'grafana': {
            'port': 3001,
            'health_endpoint': '/api/health',
            'replicas': 1
        }
    })


@dataclass
class ServiceHealth:
    """Service health information"""
    name: str
    status: ServiceStatus
    response_time_ms: Optional[float]
    cpu_usage: Optional[float]
    memory_usage: Optional[float]
    last_check: datetime
    error_message: Optional[str] = None
    uptime_seconds: Optional[float] = None


class ProductionOrchestrator:
    """Main production deployment orchestrator"""
    
    def __init__(self, config: DeploymentConfig):
        self.config = config
        self.docker_client = docker.from_env()
        self.deployment_stage = DeploymentStage.PREPARATION
        self.service_health: Dict[str, ServiceHealth] = {}
        self.deployment_start_time = None
        self.rollback_count = 0
        
        # Deployment history
        self.deployment_history: List[Dict[str, Any]] = []
        
        # Setup logging
        self._setup_logging()
        
    def _setup_logging(self):
        """Setup comprehensive logging"""
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        logging.basicConfig(
            level=logging.INFO,
            format=log_format,
            handlers=[
                logging.FileHandler(f'/tmp/{self.config.project_name}-deployment.log'),
                logging.StreamHandler()
            ]
        )
        
    async def deploy_production(self) -> bool:
        """Execute complete production deployment pipeline"""
        
        logger.info(f"Starting production deployment for {self.config.project_name}")
        self.deployment_start_time = datetime.now()
        
        try:
            # Stage 1: Preparation
            await self._stage_preparation()
            
            # Stage 2: Build
            await self._stage_build()
            
            # Stage 3: Test
            await self._stage_test()
            
            # Stage 4: Deploy
            await self._stage_deploy()
            
            # Stage 5: Validate
            await self._stage_validate()
            
            # Stage 6: Monitor
            await self._stage_monitor()
            
            # Stage 7: Complete
            self.deployment_stage = DeploymentStage.COMPLETE
            
            deployment_time = (datetime.now() - self.deployment_start_time).total_seconds()
            
            logger.info(f"üéâ Production deployment completed successfully in {deployment_time:.1f}s")
            
            # Record successful deployment
            self.deployment_history.append({
                'timestamp': self.deployment_start_time.isoformat(),
                'status': 'success',
                'duration_seconds': deployment_time,
                'services_deployed': list(self.config.services.keys()),
                'rollback_count': self.rollback_count
            })
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Production deployment failed: {e}")
            await self._handle_deployment_failure(e)
            return False
            
    async def _stage_preparation(self):
        """Preparation stage: validate environment and prerequisites"""
        
        self.deployment_stage = DeploymentStage.PREPARATION
        logger.info("Stage 1: Preparation - Validating environment")
        
        # Check Docker availability
        try:
            self.docker_client.ping()
            logger.info("‚úì Docker daemon is running")
        except Exception as e:
            raise RuntimeError(f"Docker daemon not available: {e}")
            
        # Check compose file exists
        compose_path = Path(self.config.compose_file)
        if not compose_path.exists():
            raise FileNotFoundError(f"Compose file not found: {self.config.compose_file}")
        logger.info(f"‚úì Compose file found: {self.config.compose_file}")
        
        # Validate compose file
        try:
            with open(compose_path, 'r') as f:
                compose_config = yaml.safe_load(f)
                
            # Check required services
            services = compose_config.get('services', {})
            required_services = ['frontend', 'backend']
            
            for service in required_services:
                if service not in services:
                    raise ValueError(f"Required service '{service}' not found in compose file")
                    
            logger.info(f"‚úì Compose file validated: {len(services)} services defined")
            
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid compose file: {e}")
            
        # Check system resources
        await self._check_system_resources()
        
        # Check network connectivity
        await self._check_network_connectivity()
        
        logger.info("‚úì Preparation stage completed successfully")
        
    async def _check_system_resources(self):
        """Check available system resources"""
        
        try:
            import psutil
            
            # Check CPU
            cpu_count = psutil.cpu_count()
            if cpu_count < 2:
                raise RuntimeError(f"Insufficient CPU cores: {cpu_count} (minimum 2 required)")
            logger.info(f"‚úì CPU cores available: {cpu_count}")
            
            # Check memory
            memory = psutil.virtual_memory()
            memory_gb = memory.total / (1024**3)
            if memory_gb < 4:
                raise RuntimeError(f"Insufficient memory: {memory_gb:.1f}GB (minimum 4GB required)")
            logger.info(f"‚úì Memory available: {memory_gb:.1f}GB")
            
            # Check disk space
            disk = psutil.disk_usage('/')
            disk_free_gb = disk.free / (1024**3)
            if disk_free_gb < 10:
                raise RuntimeError(f"Insufficient disk space: {disk_free_gb:.1f}GB (minimum 10GB required)")
            logger.info(f"‚úì Disk space available: {disk_free_gb:.1f}GB")
            
        except ImportError:
            logger.warning("psutil not available - skipping resource checks")
            
    async def _check_network_connectivity(self):
        """Check network connectivity for external dependencies"""
        
        test_urls = [
            'https://hub.docker.com',
            'https://registry-1.docker.io',
        ]
        
        for url in test_urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    logger.info(f"‚úì Network connectivity to {url}")
                else:
                    logger.warning(f"Network connectivity issue to {url}: {response.status_code}")
            except requests.RequestException as e:
                logger.warning(f"Network connectivity test failed for {url}: {e}")
                
    async def _stage_build(self):
        """Build stage: build Docker images"""
        
        self.deployment_stage = DeploymentStage.BUILD
        logger.info("Stage 2: Build - Building Docker images")
        
        build_cmd = [
            'docker-compose',
            '-f', self.config.compose_file,
            'build',
            '--no-cache',
            '--parallel'
        ]
        
        logger.info(f"Running build command: {' '.join(build_cmd)}")
        
        process = await asyncio.create_subprocess_exec(
            *build_cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            error_msg = f"Build failed: {stderr.decode()}")
            logger.error(error_msg)
            raise RuntimeError(error_msg)
            
        logger.info("‚úì Docker images built successfully")
        logger.info(f"Build output: {stdout.decode()[-500:]}")
        
    async def _stage_test(self):
        """Test stage: run automated tests"""
        
        self.deployment_stage = DeploymentStage.TEST
        logger.info("Stage 3: Test - Running automated tests")
        
        # Run unit tests
        test_commands = [
            ['python3', '-m', 'pytest', 'tests/', '-x', '--tb=short'],
            ['npm', 'test', '--', '--watchAll=false']
        ]
        
        for cmd in test_commands:
            try:
                logger.info(f"Running test command: {' '.join(cmd)}")
                
                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                stdout, stderr = await process.communicate()
                
                if process.returncode == 0:
                    logger.info(f"‚úì Tests passed: {' '.join(cmd[:2])}")
                else:
                    logger.warning(f"Tests failed: {stderr.decode()[-200:]}")
                    
            except FileNotFoundError:
                logger.warning(f"Test command not found: {' '.join(cmd[:2])}")
            except Exception as e:
                logger.warning(f"Test execution error: {e}")
                
        logger.info("‚úì Test stage completed")
        
    async def _stage_deploy(self):
        """Deploy stage: deploy services"""
        
        self.deployment_stage = DeploymentStage.DEPLOY
        logger.info("Stage 4: Deploy - Deploying services to production")
        
        # Stop existing services (if any)
        await self._stop_existing_services()
        
        # Deploy services
        deploy_cmd = [
            'docker-compose',
            '-f', self.config.compose_file,
            'up',
            '-d',
            '--remove-orphans',
            '--force-recreate'
        ]
        
        logger.info(f"Running deploy command: {' '.join(deploy_cmd)}")
        
        process = await asyncio.create_subprocess_exec(
            *deploy_cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            error_msg = f"Deployment failed: {stderr.decode()}"
            logger.error(error_msg)
            raise RuntimeError(error_msg)
            
        logger.info("‚úì Services deployed successfully")
        
        # Wait for services to start
        await asyncio.sleep(10)
        
    async def _stop_existing_services(self):
        """Stop existing services gracefully"""
        
        logger.info("Stopping existing services...")
        
        stop_cmd = [
            'docker-compose',
            '-f', self.config.compose_file,
            'down',
            '--volumes',
            '--remove-orphans'
        ]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *stop_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            await process.communicate()
            logger.info("‚úì Existing services stopped")
            
        except Exception as e:
            logger.warning(f"Error stopping existing services: {e}")
            
    async def _stage_validate(self):
        """Validate stage: check service health"""
        
        self.deployment_stage = DeploymentStage.VALIDATE
        logger.info("Stage 5: Validate - Checking service health")
        
        # Wait for services to fully start
        await asyncio.sleep(30)
        
        # Check each service health
        validation_timeout = time.time() + self.config.health_check_timeout
        
        while time.time() < validation_timeout:
            all_healthy = True
            
            for service_name, service_config in self.config.services.items():
                health = await self._check_service_health(service_name, service_config)
                self.service_health[service_name] = health
                
                if health.status != ServiceStatus.HEALTHY:
                    all_healthy = False
                    logger.warning(f"Service {service_name} not healthy: {health.status.value}")
                else:
                    logger.info(f"‚úì Service {service_name} is healthy")
                    
            if all_healthy:
                logger.info("‚úì All services are healthy")
                break
                
            await asyncio.sleep(10)
            
        else:
            # Timeout reached
            unhealthy_services = [
                name for name, health in self.service_health.items()
                if health.status != ServiceStatus.HEALTHY
            ]
            raise RuntimeError(f"Health check timeout. Unhealthy services: {unhealthy_services}")
            
    async def _check_service_health(self, service_name: str, service_config: Dict[str, Any]) -> ServiceHealth:
        """Check health of a specific service"""
        
        port = service_config.get('port')
        health_endpoint = service_config.get('health_endpoint', '/health')
        
        try:
            # Try to get service container
            containers = self.docker_client.containers.list(
                filters={'label': f'com.docker.compose.service={service_name}'}
            )
            
            if not containers:
                return ServiceHealth(
                    name=service_name,
                    status=ServiceStatus.STOPPED,
                    response_time_ms=None,
                    cpu_usage=None,
                    memory_usage=None,
                    last_check=datetime.now(),
                    error_message="Container not found"
                )
                
            container = containers[0]
            container.reload()  # Get latest status
            
            # Check container status
            if container.status != 'running':
                return ServiceHealth(
                    name=service_name,
                    status=ServiceStatus.UNHEALTHY,
                    response_time_ms=None,
                    cpu_usage=None,
                    memory_usage=None,
                    last_check=datetime.now(),
                    error_message=f"Container status: {container.status}"
                )
                
            # Check HTTP health endpoint
            if port and health_endpoint:
                start_time = time.time()
                
                try:
                    response = requests.get(
                        f'http://localhost:{port}{health_endpoint}',
                        timeout=10
                    )
                    
                    response_time_ms = (time.time() - start_time) * 1000
                    
                    if response.status_code == 200:
                        status = ServiceStatus.HEALTHY
                        error_message = None
                    else:
                        status = ServiceStatus.DEGRADED
                        error_message = f"HTTP {response.status_code}"
                        
                except requests.RequestException as e:
                    response_time_ms = (time.time() - start_time) * 1000
                    status = ServiceStatus.UNHEALTHY
                    error_message = str(e)
                    
            else:
                # No HTTP check, just check container status
                response_time_ms = None
                status = ServiceStatus.HEALTHY if container.status == 'running' else ServiceStatus.UNHEALTHY
                error_message = None
                
            # Get resource usage
            try:
                stats = container.stats(stream=False)
                cpu_usage = self._calculate_cpu_usage(stats)
                memory_usage = stats['memory_stats']['usage'] / stats['memory_stats']['limit']
            except:
                cpu_usage = None
                memory_usage = None
                
            return ServiceHealth(
                name=service_name,
                status=status,
                response_time_ms=response_time_ms,
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                last_check=datetime.now(),
                error_message=error_message
            )
            
        except Exception as e:
            return ServiceHealth(
                name=service_name,
                status=ServiceStatus.UNKNOWN,
                response_time_ms=None,
                cpu_usage=None,
                memory_usage=None,
                last_check=datetime.now(),
                error_message=str(e)
            )
            
    def _calculate_cpu_usage(self, stats: Dict[str, Any]) -> Optional[float]:
        """Calculate CPU usage percentage from Docker stats"""
        try:
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - \
                       stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - \
                          stats['precpu_stats']['system_cpu_usage']
            
            if system_delta > 0:
                cpu_usage = (cpu_delta / system_delta) * len(stats['cpu_stats']['cpu_usage']['percpu_usage'])
                return min(cpu_usage, 1.0)  # Cap at 100%
                
        except (KeyError, ZeroDivisionError):
            pass
            
        return None
        
    async def _stage_monitor(self):
        """Monitor stage: setup monitoring and alerting"""
        
        self.deployment_stage = DeploymentStage.MONITOR
        logger.info("Stage 6: Monitor - Setting up monitoring and alerting")
        
        if not self.config.monitoring_enabled:
            logger.info("Monitoring disabled - skipping")
            return
            
        # Check monitoring services
        monitoring_services = ['prometheus', 'grafana']
        
        for service in monitoring_services:
            if service in self.config.services:
                health = await self._check_service_health(service, self.config.services[service])
                if health.status == ServiceStatus.HEALTHY:
                    logger.info(f"‚úì Monitoring service {service} is running")
                else:
                    logger.warning(f"Monitoring service {service} is not healthy: {health.status.value}")
                    
        # Setup alerting rules (if Prometheus is available)
        await self._setup_alerting()
        
        logger.info("‚úì Monitoring stage completed")
        
    async def _setup_alerting(self):
        """Setup alerting rules and notifications"""
        
        # Check if Prometheus is running
        try:
            response = requests.get('http://localhost:9090/-/healthy', timeout=5)
            if response.status_code == 200:
                logger.info("‚úì Prometheus is available for alerting")
                
                # Here you could setup alerting rules, webhook notifications, etc.
                # For now, we'll just log that alerting is ready
                logger.info("‚úì Alerting system is ready")
                
        except requests.RequestException:
            logger.warning("Prometheus not available - alerting disabled")
            
    async def _handle_deployment_failure(self, error: Exception):
        """Handle deployment failure with rollback"""
        
        self.deployment_stage = DeploymentStage.FAILED
        logger.error(f"Deployment failed at stage {self.deployment_stage.value}: {error}")
        
        # Record failed deployment
        deployment_time = (datetime.now() - self.deployment_start_time).total_seconds() if self.deployment_start_time else 0
        
        self.deployment_history.append({
            'timestamp': datetime.now().isoformat(),
            'status': 'failed',
            'duration_seconds': deployment_time,
            'error_message': str(error),
            'failed_stage': self.deployment_stage.value
        })
        
        # Attempt rollback if not at max attempts
        if self.rollback_count < self.config.max_rollback_attempts:
            logger.info(f"Attempting rollback (attempt {self.rollback_count + 1}/{self.config.max_rollback_attempts})")
            await self._rollback_deployment()
        else:
            logger.error(f"Maximum rollback attempts reached ({self.config.max_rollback_attempts})")
            
    async def _rollback_deployment(self):
        """Rollback to previous working deployment"""
        
        self.deployment_stage = DeploymentStage.ROLLBACK
        self.rollback_count += 1
        
        logger.info("Rolling back deployment...")
        
        try:
            # Stop current services
            await self._stop_existing_services()
            
            # Here you could restore from backup, deploy previous version, etc.
            # For now, we'll just ensure services are stopped cleanly
            
            logger.info("‚úì Rollback completed")
            
        except Exception as e:
            logger.error(f"Rollback failed: {e}")
            
    def get_deployment_status(self) -> Dict[str, Any]:
        """Get current deployment status"""
        
        return {
            'stage': self.deployment_stage.value,
            'start_time': self.deployment_start_time.isoformat() if self.deployment_start_time else None,
            'duration_seconds': (datetime.now() - self.deployment_start_time).total_seconds() if self.deployment_start_time else 0,
            'service_health': {
                name: {
                    'status': health.status.value,
                    'response_time_ms': health.response_time_ms,
                    'cpu_usage': health.cpu_usage,
                    'memory_usage': health.memory_usage,
                    'last_check': health.last_check.isoformat(),
                    'error_message': health.error_message
                }
                for name, health in self.service_health.items()
            },
            'rollback_count': self.rollback_count,
            'deployment_history': self.deployment_history[-5:]  # Last 5 deployments
        }
        
    def generate_deployment_report(self) -> str:
        """Generate comprehensive deployment report"""
        
        status = self.get_deployment_status()
        
        report_lines = [
            f"# Production Deployment Report - {self.config.project_name}",
            f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            f"## Deployment Status: {status['stage'].upper()}",
            f"Start Time: {status['start_time']}",
            f"Duration: {status['duration_seconds']:.1f} seconds",
            f"Rollback Count: {status['rollback_count']}",
            "",
            "## Service Health"
        ]
        
        for service_name, health in status['service_health'].items():
            report_lines.extend([
                f"### {service_name}",
                f"- Status: {health['status']}",
                f"- Response Time: {health['response_time_ms']:.1f}ms" if health['response_time_ms'] else "- Response Time: N/A",
                f"- CPU Usage: {health['cpu_usage']:.1%}" if health['cpu_usage'] else "- CPU Usage: N/A",
                f"- Memory Usage: {health['memory_usage']:.1%}" if health['memory_usage'] else "- Memory Usage: N/A",
                f"- Last Check: {health['last_check']}",
                f"- Error: {health['error_message']}" if health['error_message'] else "",
                ""
            ])
            
        if status['deployment_history']:
            report_lines.extend([
                "## Recent Deployments",
                ""
            ])
            
            for i, deployment in enumerate(status['deployment_history'], 1):
                report_lines.extend([
                    f"{i}. {deployment['timestamp']} - {deployment['status']} ({deployment['duration_seconds']:.1f}s)",
                    f"   Error: {deployment.get('error_message', 'None')}",
                    ""
                ])
                
        return "\n".join(report_lines)


async def main():
    """Main deployment orchestration"""
    
    # Configuration
    config = DeploymentConfig(
        environment="production",
        project_name="causal-ui-gym",
        compose_file="docker-compose.production-ready.yml",
        health_check_timeout=300,
        monitoring_enabled=True,
        auto_scaling_enabled=True
    )
    
    # Create orchestrator
    orchestrator = ProductionOrchestrator(config)
    
    try:
        # Deploy to production
        success = await orchestrator.deploy_production()
        
        if success:
            print("\nüéâ Production deployment completed successfully!")
            print("\nDeployment Report:")
            print(orchestrator.generate_deployment_report())
            
            # Keep monitoring (in production, this would be a separate service)
            print("\nMonitoring deployment... (Ctrl+C to stop)")
            
            while True:
                await asyncio.sleep(60)
                status = orchestrator.get_deployment_status()
                healthy_services = sum(
                    1 for health in status['service_health'].values()
                    if health['status'] == 'healthy'
                )
                total_services = len(status['service_health'])
                print(f"Health check: {healthy_services}/{total_services} services healthy")
                
        else:
            print("\n‚ùå Production deployment failed!")
            print("\nDeployment Report:")
            print(orchestrator.generate_deployment_report())
            
    except KeyboardInterrupt:
        print("\nüõë Deployment monitoring stopped by user")
    except Exception as e:
        print(f"\n‚ùå Deployment orchestration error: {e}")
        

if __name__ == "__main__":
    asyncio.run(main())
